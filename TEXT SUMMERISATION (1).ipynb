{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOPH5avybqxmqKTQyF92AnY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZA8nn_fqjP0"},"outputs":[],"source":["What is Text Summarization?\n","\n","Text summarization is the process of generating a shorter version of a text that preserves its main meaning, key ideas, and intent.\n","\n","It‚Äôs a form of text generation, where the model takes a long input (like an article, report, or paragraph) and generates a concise summary, just like a human would do.\n","\n","Two Main Types of Text Summarization\n","\n","Extractive Summarization\n","The model selects important sentences or phrases directly from the original text.\n","\n","It does not generate new sentences; it simply extracts and rearranges existing content.\n","\n","Example: Input:\n","\n","\"The Indian Space Research Organisation (ISRO) launched the Chandrayaan-3 mission to explore the Moon's south pole. The mission aims to demonstrate safe landing and roving on the lunar surface.\" Extractive summary: \"ISRO launched Chandrayaan-3 to explore the Moon's south pole.\"\n","\n",". Abstractive Summarization\n","\n","The model understands the text and generates new sentences that express the same meaning ‚Äî like how humans paraphrase.\n","\n","It‚Äôs a truly generative approach.\n","\n","Example: Input:\n","\n","\"The Indian Space Research Organisation (ISRO) launched the Chandrayaan-3 mission to explore the Moon's south pole. The mission aims to demonstrate safe landing and roving on the lunar surface.\" Abstractive summary: \"ISRO‚Äôs Chandrayaan-3 mission targets a soft landing on the Moon‚Äôs south pole.\"\n","\n","üß© Common models:\n","\n","Transformer-based models like T5, BART, PEGASUS, GPT, LLaMA, etc.\n","\n","‚öôÔ∏è How It Works in Generative AI\n","\n","Generative AI models (like GPT, BART, T5) are trained on large datasets of (document, summary) pairs.\n","\n","Input: A long text.\n","\n","Encoder: Understands the meaning of the input text.\n","\n","Decoder: Generates a shorter version that preserves meaning.\n","\n","Training objective: Minimize the difference between generated summary and reference summary.\n","\n","Applications of Text Summarization\n","\n","News summarization ‚Äì Summarizing news articles.\n","\n","Research summarization ‚Äì Summarizing scientific papers or abstracts.\n","\n","Legal/medical summarization ‚Äì Condensing long legal documents or patient histories.\n","\n","Customer service ‚Äì Summarizing support tickets or chat transcripts.\n","\n","Meeting summarization ‚Äì Summarizing transcripts from meetings or lectures.\n","\n","\n","[ ]\n","from transformers import pipeline\n","\n","summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n","\n","text = \"\"\"The global shift toward renewable energy is accelerating,\n","driven by concerns over climate change and energy security. Solar\n","and wind power installations have reached record levels worldwide.\"\"\"\n","\n","summary = summarizer(text, max_length=30, min_length=10, do_sample=False)\n","print(summary[0])\n","\n","Device set to use cpu\n","{'summary_text': 'Solar and wind power installations have reached record levels worldwide. The global shift toward renewable energy is accelerating.'}\n","\n","[ ]\n","#from transformers import pipeline\n","This line imports the pipeline function from the Hugging Face Transformers library.\n","\n","The Transformers library provides pre-trained models for:\n","\n","Text summarization\n","\n","Text classification\n","\n","Sentiment analysis\n","\n","Translation\n","\n","Image classification\n","\n","Question answering\n","\n","Text generation (GPT-like models)\n","\n","Many more‚Ä¶\n","\n","The pipeline function is a shortcut tool that makes it very easy to use pre-trained models without needing to write complex code.\n","\n","‚úÖ Why use pipeline?\n","\n","Because it:\n","\n","‚úî Loads a pre-trained model automatically\n","\n","You don‚Äôt need to manually load the tokenizer and model.\n","\n","‚úî Automatically handles tokenization\n","\n","It converts your text to tokens internally.\n","\n","‚úî Runs the model\n","\n","‚úî Returns clean, human-readable output\n","\n","do_sample=False\n","\n","This disables sampling and uses greedy decoding.\n","\n","üîç What is greedy decoding?\n","\n","The model picks the highest-probability next word at each step.\n","\n","Output is deterministic ‚Üí same input ‚Üí same summary every time.\n","\n","No randomness.\n","\n","If you set do_sample=True, the model would generate more diverse and creative summaries (but may vary each time).\n","\n","\n"]}]}